import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm

# Define the Rosenbrock's Banana Function
def banana(r):
    x, y = r
    return (1 - x)**2 + 100*(y - x**2)**2

# Define the gradient of the banana function
def banana_grad(r):
    x, y = r
    dfdx = -2*(1 - x) - 400*x*(y - x**2)
    dfdy = 200*(y - x**2)
    return np.array([dfdx, dfdy])

# Implement gradient descent optimization
def gradientDescent(df, r0, eta, n_steps):
    trajectory = np.zeros((n_steps+1, 2))
    r = r0
    trajectory[0] = r
    for i in range(n_steps):
        gradient = df(r)
        r = r - eta*gradient
        trajectory[i+1] = r
    return trajectory

# Initialize parameters for the plot
n_points = 1000
x = np.linspace(-2, 2, n_points)
y = np.linspace(-1, 3, n_points)
X, Y = np.meshgrid(x, y)
data = banana(np.array([X, Y]))

# Plot the banana function as the backdrop
plt.figure()
im = plt.imshow(data, extent=(-2, 2, -1, 3), origin='lower', cmap=cm.gray)

# Set the initial point
r0 = np.array([0.9, 1])

# Different step sizes to explore
etas = [0.001, 0.002, 0.005]

# Plot trajectories for each step size
for eta in etas:
    trajectory = gradientDescent(banana_grad, r0, eta, 1000)
    plt.plot(trajectory[:,0], trajectory[:,1], label=f'eta={eta}')

plt.title("Gradient Descent Optimization Trajectories for Rosenbrock's Banana Function")
plt.xlabel("x")
plt.ylabel("y")
plt.legend()
plt.show()