import numpy as np
import matplotlib.pyplot as plt

# Define the Banana function and its derivative
def banana(r):
    x, y = r
    return (1 - x)**2 + 100*(y - x**2)**2

def banana_grad(r):
    x, y = r
    dfdx = -2*(1 - x) - 400*x*(y - x**2)
    dfdy = 200*(y - x**2)
    return np.array([dfdx, dfdy])

# Initialize parameters for the plot
x = np.linspace(-2, 2, 100)
y = np.linspace(-1, 3, 100)
X, Y = np.meshgrid(x, y)

# Placeholder for data
data = np.zeros_like(X)

# Compute banana function on the grid
for i in range(X.shape[0]):
    for j in range(X.shape[1]):
        data[i, j] = banana([X[i, j], Y[i, j]])

# Implement gradient descent
def gradient_descent(start, eta, max_iter):
    r = np.array(start, dtype=float)
    path = [r.copy()]
    for _ in range(max_iter):
        grad = banana_grad(r)
        r -= eta * grad
        path.append(r.copy())
        # Break if the step size becomes too small
        if np.linalg.norm(grad) * eta < 1e-6:
            break
    return np.array(path)

# Plot the results
plt.contourf(X, Y, data, levels=np.logspace(-1, 3, 30), cmap='viridis')
plt.colorbar()

# Starting point
r0 = [0.2, 1]
plt.scatter(r0[0], r0[1], color='red', zorder=5, label='Start')

# Different step sizes
etas = [0.001, 0.005, 0.01]
colors = ['r', 'g', 'b']
max_iter = 5000

for eta, color in zip(etas, colors):
    path = gradient_descent(r0, eta, max_iter)
    plt.plot(path[:, 0], path[:, 1], color=color, label=f'eta={eta}')

plt.xlabel('x')
plt.ylabel('y')
plt.title('Gradient Descent on Rosenbrock\'s Banana Function')
plt.legend()
plt.show()